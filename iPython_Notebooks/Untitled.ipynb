{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Dependencies--#\n",
    "\n",
    "#-- Data Cleaning Libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#-- Data Visualization Libraries:\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns #--just in case we need it, probably won't\n",
    "\n",
    "\n",
    "#-- Web Scraping Libraries:\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings for accessing Website\n",
    "\n",
    "executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "\n",
    "browser = Browser ('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-defining Variables for NBA scrape\n",
    "\n",
    "#Empty DataFrame for NBA\n",
    "NBA_draftdata_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "#Reference to names\n",
    "NBA_refer = \"basketball-reference\"\n",
    "\n",
    "#URL\n",
    "NBA_url = \"https://www.basketball-reference.com/play-index/tiny.fcgi?id=BRvVj#stats::none\"\n",
    "\n",
    "# #Create Empty List for years we want to scrape for\n",
    "# years = [\"1990\", \"1991\", \"1992\", \"1993\", \"1994\", \"1995\",\\\n",
    "#          \"1996\", \"1997\", \"1998\", \"1999\", \"2000\",\"2001\", \\\n",
    "#          \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\",\\\n",
    "#          \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\",\\\n",
    "#          \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\"]\n",
    "\n",
    "offset=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our function for scraping NBA Data---> ** need to come back to this and finish it off\n",
    "def scrape_nba_draft_data(page_url):\n",
    "    #URL's for both NBA and NCAA\n",
    "    #Reference global variable: NBA_draftdata_df\n",
    "    global NBA_draftdata_df\n",
    "    \n",
    "    for i  in years:\n",
    "\n",
    "        #Set the rest of the url\n",
    "        url = f\"https://www.basketball-reference.com/play-index/draft_finder.cgi?request=1&year_min=1990&year_max=\\\n",
    "              &round_min=&round_max=&pick_overall_min=&pick_overall_max=&franch_id=&college_id=0&is_active=&is_hof=\\\n",
    "              &pos_is_g=Y&pos_is_gf=Y&pos_is_f=Y&pos_is_fg=Y&pos_is_fc=Y&pos_is_c=Y&pos_is_cf=Y&c1stat=&c1comp=&c1val=\\\n",
    "              &c2stat=&c2comp=&c2val=&c3stat=&c3comp=&c3val=&c4stat=&c4comp=&c4val=&order_by=year_id&order_by_asc=\\\n",
    "              &offset={offset}\"\n",
    "\n",
    "        #Visit the NBA Web page\n",
    "        browser.visit(url)\n",
    "\n",
    "        #Retrieve the html for the web page\n",
    "        html = browser.html\n",
    "\n",
    "        #Use pandas to read html\n",
    "        year_html = pd.read_html(html, header = 0)\n",
    "\n",
    "        #Get the second Table with all of the Data\n",
    "        year_html = year_html[1]\n",
    "\n",
    "        #Convert into DataFrame\n",
    "        year_df = pd.DataFrame(year_html)\n",
    "\n",
    "        #Delete Column of Ranking: \"Rk\"\n",
    "        year_df = year_df.rename(columns=({\"Rk\" : \"Year\"}))\n",
    "\n",
    "        #Apply the year to the Year column for each row\n",
    "        year_df[\"Year\"] = year_df[\"Year\"].apply(lambda x: year)\n",
    "\n",
    "\n",
    "\n",
    "        #Append to main DataFrame: NBA_game_df\n",
    "        if NBA_game_df.empty: \n",
    "            NBA_game_df = year_df\n",
    "        else: \n",
    "            NBA_game_df = NBA_game_df.append(year_df, ignore_index = True)\n",
    "\n",
    "        #hoooldd on wait a second, let me put some sleep in it\n",
    "        time.sleep(1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
